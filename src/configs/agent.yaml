# Example Flexo Configuration
# This configuration demonstrates key features and common settings

# Basic agent configuration
name: flexo
history_limit: 4
logging_level: INFO
max_streaming_iterations: 3 # Number of times the agent is allowed to return to streaming (e.g. after tools execution)

# Response timeouts
timeouts:
  model_response_timeout: 60

# System prompt defining agent behavior and capabilities
system_prompt: |
  I am a helpful AI assistant focused on clear, accurate, and direct communication. 
  I solve problems systematically and explain my reasoning when needed. 
  I maintain a professional yet approachable tone.
  
  CORE BEHAVIORS:
  - Communicate clearly and concisely
  - Break down complex problems step-by-step
  - Ask clarifying questions when truly needed
  - Acknowledge limitations and uncertainties honestly
  - Validate assumptions before proceeding
  
  TOOL USAGE:
  - Call tool(s) immediately as needed 
  - Do not reference tools or their formatting in your response
  - Use tools only when they genuinely enhance the response
  - Handle errors gracefully with clear explanations
  - Show key results and interpret them in context
  - Suggest alternatives if the primary approach fails
  
  I adapt my style to user needs while staying focused on providing valuable, 
  actionable responses.

# Core behavior settings
detection_mode: manual              # Options: manual, vendor
use_vendor_chat_completions: false  # Options: true, false

# Model Configuration
models_config:
  main_chat_model:
    # WatsonX Configuration
    vendor: watsonx-llama #watsonx-llama # Options: watsonx-llama/granite/mistral, openai, anthropic, mistral-ai
    model_id: meta-llama/llama-3-405b-instruct # Other options: mistralai/mistral-large, meta-llama/llama-3-405b-instruct, ibm/granite-3-8b-instruct
    decoding_method: greedy
    max_new_tokens: 4000
  # web_scraper_model:
  #   vendor: watsonx-llama # Options: watsonx-llama/granite/mistral, openai, anthropic, mistral-ai
  #   model_id: meta-llama/llama-3-3-70b-instruct # Other options: mistralai/mistral-large, meta-llama/llama-3-405b-instruct, ibm/granite-3-8b-instruct
  #   decoding_method: greedy
  #   max_new_tokens: 4000
  # summarizer_model:
  #   vendor: watsonx-llama
  #   model_id: meta-llama/llama-3-3-70b-instruct
  #   decoding_method: greedy
  #   max_new_tokens: 4000
  # image_model:
  #   vendor: watsonx-llama
  #   model_id: meta-llama/llama-3-2-90b-vision-instruct
  #   decoding_method: greedy
  #   max_new_tokens: 4000
    # Alternative OpenAI Configuration (uncomment to use)
    # vendor: openai
    # model_id: gpt-4-mini
    # max_tokens: 4000
    # temperature: 0.7

# Tool Configurations
tools_config:
  # Weather API Integration
  # weather_tool:
  #   endpoint_url: "https://api.openweathermap.org/data/2.5/weather"
  #   api_key_env: "OWM_API_KEY"
  
  # Wikipedia API Integration
  # wikipedia_tool:
  #   endpoint_url: "https://{lang}.wikipedia.org/api/rest_v1/page/summary/{encoded_query}"

  # RAG Tool with Elasticsearch (optional, not enabled by default)
  rag_tool:
    connector_config:
      connector_type: elasticsearch
      index_name: search-cat
      api_key_env: ES_API_KEY
      endpoint_env: ES_ENDPOINT
      top_k: 5
      timeout: 30
      max_retries: 3
      query_body:
        _source: false
        fields: ["text"]
        query:
          bool:
            must:
              - match:
                  text:
                    query: "$USER_INPUT"
                    boost: 3.5
        knn:
          field: vector
          query_vector_builder:
            text_embedding:
              model_id: thenlper__gte-base
              model_text: "$USER_INPUT"
          k: 100
          num_candidates: 150
        rank:
          rrf:
            rank_window_size: 40

  # web_scrape_tool:
  #   name: web_scraper
  #   vendor: watsonx-llama # Options: watsonx-llama/granite/mistral, openai, anthropic, mistral-ai
  #   model_id: meta-llama/llama-3-405b-instruct # Other options: mistralai/mistral-large, meta-llama/llama-3-405b-instruct, ibm/granite-3-8b-instruct
  #   decoding_method: greedy
  #   max_new_tokens: 4000
